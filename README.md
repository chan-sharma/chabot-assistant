# ðŸ¤– Chatbot Assistant

A modular, production-ready AI chatbot framework built with [OpenAI](https://platform.openai.com/), `Gradio`, and clean architecture principles.

Supports real-time streaming, dependency injection, and is designed for easy extension to other LLM providers (e.g., Claude, Mistral, etc.).

---

## ðŸ§± Features

- âœ… Real-time streaming chat using OpenAI GPT models
- âœ… Clean architecture with proper dependency injection (DI)
- âœ… Easily swappable LLM clients
- âœ… Modular service classes (`OpenAIClient`, `Aibot`, `AIAgent`)
- âœ… Markdown-formatted responses
- âœ… Testable with mocked clients
- âœ… Minimal frontend via Gradio

---

## ðŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/your-org/chatbot-assistant.git
cd chatbot-assistant 
```
### 2. Setting up the environment
```bash
# Using Poetry
poetry install

# OR using pip
pip install -r requirements.txt
```
### 3. Add your OpenAI API key
```bash
export OPENAI_API_KEY="your-api-key-here"
```
## Project Structure
```bash
chatbot_assistant/
â”œâ”€â”€ app.py                         # Gradio frontend entry point
â”œâ”€â”€ agent_orchestrator.py         # Orchestrates the AI bot
â”œâ”€â”€ ai_bot.py                     # Handles interaction with OpenAIClient
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ open_ai_client.py         # Streaming wrapper for OpenAI Chat API
â”‚   â”œâ”€â”€ config.py                 # Centralized configuration
â”‚   â””â”€â”€ system_prompt_global.py   # Shared system prompts
tests/
â”œâ”€â”€ test_aibot.py                 # Unit tests for Aibot logic
â”œâ”€â”€ test_open_ai_client.py        # Unit tests with mocked LLM
.env                              # Optional â€“ for API keys
README.md                         # You're here

```
## Running the APP
```bash
python app.py
```